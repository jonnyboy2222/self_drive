{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233731e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547aa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"yolov8n.pt\"\n",
    "\n",
    "\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ffdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "else:\n",
    "    model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97372b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e898bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "ret, frame = camera.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a48fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e0ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copyframe = frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eafb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(frame, stream=False, verbose=False, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180147d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[176, 174, 167],\n",
       "         [176, 174, 167],\n",
       "         [179, 172, 166],\n",
       "         ...,\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248]],\n",
       " \n",
       "        [[177, 177, 165],\n",
       "         [176, 176, 164],\n",
       "         [179, 172, 166],\n",
       "         ...,\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248]],\n",
       " \n",
       "        [[176, 176, 164],\n",
       "         [176, 176, 164],\n",
       "         [179, 172, 166],\n",
       "         ...,\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248],\n",
       "         [248, 248, 248]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[127, 127, 120],\n",
       "         [129, 129, 122],\n",
       "         [126, 127, 123],\n",
       "         ...,\n",
       "         [ 59,  70,  70],\n",
       "         [ 65,  62,  64],\n",
       "         [ 65,  62,  64]],\n",
       " \n",
       "        [[121, 120, 116],\n",
       "         [122, 121, 117],\n",
       "         [120, 122, 115],\n",
       "         ...,\n",
       "         [ 65,  71,  73],\n",
       "         [ 69,  63,  68],\n",
       "         [ 69,  63,  68]],\n",
       " \n",
       "        [[117, 117, 110],\n",
       "         [120, 120, 113],\n",
       "         [116, 116, 116],\n",
       "         ...,\n",
       "         [ 71,  83,  81],\n",
       "         [ 78,  77,  80],\n",
       "         [ 71,  70,  73]]], dtype=uint8)\n",
       " orig_shape: (480, 640)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 4.23900499993124, 'inference': 30.053146000000197, 'postprocess': 118.06038600002466}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287527ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0.], device='cuda:0')\n",
       "conf: tensor([0.8767], device='cuda:0')\n",
       "data: tensor([[101.9325, 130.2327, 549.9501, 479.2849,   0.8767,   0.0000]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (480, 640)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[325.9413, 304.7588, 448.0176, 349.0522]], device='cuda:0')\n",
       "xywhn: tensor([[0.5093, 0.6349, 0.7000, 0.7272]], device='cuda:0')\n",
       "xyxy: tensor([[101.9325, 130.2327, 549.9501, 479.2849]], device='cuda:0')\n",
       "xyxyn: tensor([[0.1593, 0.2713, 0.8593, 0.9985]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba09bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8767, device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor([101.9325, 130.2327, 549.9501, 479.2849], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes[0].conf[0], results[0].boxes[0].cls[0], results[0].boxes[0].xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda157da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = model.names\n",
    "CLASS_NAMES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3ab361",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASS_PERSON = \"person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        cls = int(box.cls[0]) # in this case, cls = 0 (person)\n",
    "        class_name = CLASS_NAMES[cls]\n",
    "\n",
    "        if class_name.lower() == TARGET_CLASS_PERSON.lower():\n",
    "            cv2.rectangle(copyframe, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{class_name}: {conf:.2f}\"\n",
    "            cv2.putText(copyframe, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35842d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"al\", copyframe)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82854f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d492f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    copyframe = frame.copy()\n",
    "    results = model(frame, stream=False, verbose=False, conf=0.5)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0]) # in this case, cls = 0 (person)\n",
    "            class_name = CLASS_NAMES[cls]\n",
    "\n",
    "            if class_name.lower() == TARGET_CLASS_PERSON.lower():\n",
    "                cv2.rectangle(copyframe, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                label = f\"{class_name}: {conf:.2f}\"\n",
    "                cv2.putText(copyframe, label, (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"detected\", copyframe)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a06b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodrive_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
